import React from 'react';
import Game from './Game.js';

import Paper from '@material-ui/core/Paper';
import Typography from '@material-ui/core/Typography';
import List from '@material-ui/core/List';
import ListItem from '@material-ui/core/ListItem';
import {withStyles} from '@material-ui/core/styles';

const styles = ({
  gameContainer: {
    paddingTop: '20px',
  },
  textContainer: {
    padding: 26,
    maxWidth: 600,
    margin: 'auto',
  }
});

class App extends React.Component {
  
  constructor(props) {
    super(props);
    this.state = {
      difficulty: 5
    }
  }

  handleOptionChange = (i) => {
    const newDifficulty = i + 1;
    console.log(`${newDifficulty} has been selected!`);
    this.setState( { difficulty: newDifficulty } );
    this.forceUpdate();
  }

  render() {
    const { classes } = this.props;
    return (
      <>
      <Paper className={classes.gameContainer}>
        <div>
          <Game
            difficulty={this.state.difficulty}
            handleRadioChange={this.handleOptionChange}
          />   
        </div>
        <div className={classes.textContainer}>
          <Typography variant='h6'>The Rook Jumping Maze</Typography>
          <Typography paragraph>Starting at the square in the upper-left corner, find a path to the "0" square in the bottom-right corner.  From each numbered square, one may move that exact number of squares horizontally or vertically.  What's the shortest path you can find?</Typography>
          <Typography variant='h6'>Generating the Maze</Typography>
          <Typography paragraph>Initially, the maze is just a randomly generated grid of numbers, not guaranteed to be easy, challenging, or even solvable! The final maze (displayed now) is generated by an artificial intelligence algorithm known as {(<strong><em>hill climbing</em></strong>)}. One non-goal square is randomly changed, and the new maze is evaluated. If it is better, it replaces the old maze. Thus, the maze climbs "uphill." This repeats until a new maze meets a certain "goodness" threshold. This evaluation is done by an {(<strong><em>objective function</em></strong>)}.</Typography>
          <Typography variant='h6'>The Objective Function</Typography>
          <Typography paragraph>The greatest creative work on this project is in defining the objective function, which takes a maze, and returns a number representing the "goodness" of the maze. The current implementation of the objective function currently only weighs solvability and shortest-solution length, which is discovered by a simple {(<strong><em>breadth-first search</em></strong>)}.</Typography>
          <Typography variant='h6'>Optimizations</Typography>
          <Typography paragraph>This project includes a few optimizations to classical algorithms, and could be expanded to include several more.
            <List>
              <ListItem><Typography><Typography variant='subtitle2' inline={true}>Initial generation</Typography> &nbsp;Opposed to truly random values in each square, the maze is initially seeded with only squares from which there exists a legal move. This drastically reduces the number of "black holes," or dead ends from which the player can't continue. That in turn increases the chance that a maze is solvable and increases the branching factor at each step, which increases complexity.</Typography></ListItem>
              <ListItem><Typography><Typography variant='subtitle2' inline={true}>Random restart</Typography> &nbsp;Random-restart hill climbing adopts the well-known adage, "If at first you don't succeed, try, try again." If the goodness of the maze hasn't passed the threshold after a certain number of iterations of the hill-climbing algorithm, the process restarts with a new initial maze.</Typography></ListItem>
            </List>
          </Typography>
        </div>
      </Paper>
      </>
    );
  }
}

export default withStyles(styles)(App);
